# 2. 全链路监控：稳定性的守护者

前端是直接面向用户的端，除了自身的工程部分，其还依赖于后端、第三方、以及整个业务链路中所有通路。

一个前端请求的处理流程，从浏览器发起请求，到服务端接收请求并返回响应，再到浏览器接收响应并渲染页面，贯穿多个不同的技术栈和系统。任何一个环节出现异常，都可能导致请求失败或响应缓慢，影响到最终的用户体验。

因此，光有前端侧的监控数据是不够的，还需要建立端到端的全链路监控体系。全链路监控是端到端追踪请求流程、发现性能瓶颈、定位异常根源的利器，是确保整个前端服务稳定运行的守护者。

## 全链路监控项

### 请求追踪

在请求从前端发起时，植入唯一的 TraceID。该 ID 贯穿整个请求的处理过程，前后端服务通过传递该 ID，将一次完整的请求串联起来。利用 OpenTelemetry 等开放标准，统一不同服务的追踪数据格式，实现全链路可观测。

### 接口监控

在前后端的接口调用处，监控请求量、成功率、错误码、响应时间等指标。当某个接口的关键指标出现异常时，及时报警通知相关责任人。对高频调用、高敏感度的核心接口，设置更加严格的监控规则。

相关指标：

- 接口网络异常
- 接口业务异常（HTTP status 为 200，但 body 里返回的业务状态码不符合预期）
- 接口响应耗时

### 网络监控

前端请求的响应时间，很大一部分消耗在网络传输上。通过 Navigation Timing、Resource Timing 等 API，采集请求各个阶段的耗时，如 DNS 解析、TCP 连接、SSL 握手、响应等待等。当某个阶段耗时异常时，说明网络环节可能存在问题。

### 服务监控

除了前端自身，还需要监控前端所依赖的后端服务的运行状态，包括接口的可用性、负载情况等。当某个服务出现不可用、响应变慢等情况时，前端要能快速感知，并触发相应的告警和降级策略，避免影响到用户。服务的监控更多的依赖于后端或者 SRE 同学的构建，只是从前端的角度，其作为我们监控的一个关联方或者说链路中的一环。

前端可以采集接口相关数据如接口网络异常、接口业务异常、接口响应耗时等，从前端角度建立监控告警。

SRE 会采集接入层如 Nginx 的访问日志，如请求网络异常、请求（下游）响应耗时等。

### 业务监控

从业务的视角设置监控，如用户的登录成功率、订单的支付转化率等。一旦这些关键业务指标出现异常波动，就有可能说明某个环节出了问题，需要及时介入分析和处置。

### 智能关联

海量的监控指标，很容易产生“告警风暴”，淹没真正的问题。利用机器学习算法，智能关联不同来源的监控数据。比如，当某个接口响应缓慢，再结合网络监控数据，发现同一时间网络延迟升高，响应时间和延迟的波动趋势一致，那问题的根源可能在于网络，而非程序代码。

## 构建全链路监控系统

全链路监控从整体上提升了前端异常的可发现性，能够以更全局、更系统的视角审视请求的健康状况。它让监控不再局限于单一的技术范畴，而是拓展到了端到端的业务链路，从而更加贴近用户的真实体验。

以上是我们需要监控的部分，但是如何从头开始构建整个全链路监控系统，大概需要有如下的步骤。

### 需求调研与方案设计

每一家公司对于监控的诉求都不一样，特别是全链路这种大而全的监控系统，往往是一个牵连甚广的事项，最好从上到下来实施落地。

而且，需要结合当前业务所处的阶段，当前业务形态来明确需要做什么，以及能做什么。

这个过程主要是以下两个部分：

- **梳理监控需求**：深入调研业务和技术团队，了解他们对监控的需求和期望。识别关键的业务流程和核心技术指标，明确监控的目标和范围。这一点特别重要，明确目标，考虑整体的 ROI，以及结合公司战略。

- **设计监控方案**：基于调研结果，设计全链路监控的整体方案。方案要覆盖前端、网络、后端、基础设施等各个环节，涵盖性能监控、错误监控、业务监控等各个维度。要明确数据采集、数据处理、数据存储、可视化展示、告警通知等各个流程的技术选型和实现方案。这些内容是要考虑，但是并不是要一次性做完，全链路监控和稳定性建设一样都是一个长期的事情，需要不停的打磨和持续的投入。

### 监控 SDK  开发

要想做监控系统，其作为一个通用的能力，需要有特定的 SDK，以及系统支撑，从规范和模型开始保持统一，这样后续的的报表、监控等才能统一处理和跟进。

- **定义数据模型**：基于监控需求，设计监控数据的结构化模型。数据模型要能覆盖各类监控场景，如性能指标、错误日志、请求追踪等，同时要易于扩展和维护。

- **开发采集 SDK**：针对不同的监控对象和环境，如 JS 端、Node 端、iOS 端、Android 端等，开发对应的数据采集 SDK。SDK 负责以最小侵入的方式，采集各种监控指标。要保证 SDK 的稳定性和性能，不影响业务功能。

- **设计数据上报**：采集到的监控数据，要高效、可靠地上报到服务端。设计合理的数据上报策略，如本地缓存、定时上报、断点续传等，提升数据的完整性。数据格式要轻量化，减少网络传输的开销。

### 搭建日志和监控服务

和 SDK 以及数据模型相关的是日志以及整个监控系统，大概包括如下的部分：

- **数据接收服务**：搭建数据接收服务，如 Nginx、Kafka 等，负责接收 SDK 上报的监控数据。服务要能承载大量并发的数据写入，保证数据不丢失。

- **数据处理服务**：搭建数据处理服务，如 Flink、Spark 等，对接收到的原始监控数据进行清洗、转换、聚合，生成各类统计指标。处理过程要尽可能实时，减少数据处理的延迟。

- **数据存储服务**：根据数据的特性和查询需求，选择合适的存储服务。如对实时性要求高的核心指标，存入时序数据库如 InfluxDB，或 ClickHouse；对聚合统计数据，存入 ElasticSearch；对明细数据，存入 Hive、Druid 等。

- **配置告警规则**：基于业务的 SLA 要求，配置各类监控指标的告警规则。如设置核心性能指标的阈值、错误率的上限等。告警规则要定期回顾，持续优化。

### 可视化展示搭建

数据存储及分析后，需要展示出来，通用我们会使用监控大盘、报表以及告警的形式。

- **监控大盘开发**：使用 Grafana 等可视化工具，开发监控指标的展示大盘。大盘布局要清晰，核心指标放在显著位置。图表类型要直观，如用仪表盘展示实时数据，用折线图展示趋势数据。

- **监控报表开发**：使用 BI 工具（优先考虑公司内已有的），开发监控数据的统计报表。报表维度要全面，如按时间、地域、终端等多个维度统计核心指标。报表要定期发送给相关干系人。

- **监控告警开发**：接入钉钉、Slack、短信、电话等告警渠道。当监控指标触发告警规则时，自动发送告警通知。告警内容要明确，如告警对象、告警原因、告警等级等。同时要有告警升级和恢复的机制。

以上的搭建过程，可以结合公司实际情况，使用开源项目搭建，也可以考虑使用公有云服务提供的日志、监控等组件，或者购买专业的第三方日志监控系统，可以更快的实现想要的效果。

在搭建完以上这些后，后续可以考虑根因分析模型，故障自愈机制，以及对于监控的标准处理流程，这些处理流程我们在后面的流程机制中再展开聊。

全链路监控系统的构建涉及方方面面，需要前端、后端、算法、运维等各领域通力合作。从需求调研，到方案设计，再到开发搭建、优化运营，每一步都要细之又细。尤为关键的是，监控系统的构建不是一蹴而就的，而是一个持续迭代、不断优化的过程。只有持之以恒地优化和完善，才能真正发挥监控系统的价值，为业务保驾护航。
